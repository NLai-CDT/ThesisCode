{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc50ed09-54d9-477a-ae32-d2f2aa4caa3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/uxlfoundation/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "\n",
    "patch_sklearn()\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.covariance import LedoitWolf\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from pyriemann.estimation import Covariances\n",
    "from pyriemann.classification import TSclassifier\n",
    "from pyriemann.spatialfilters import CSP\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from pyriemann.utils.mean import mean_logeuclid\n",
    "#from pyriemann.classification import SVC\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import h5py\n",
    "\n",
    "import time\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df5bffc5-41e2-4e52-9cf6-6b97cfcf8158",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6c1b51-e3f8-4dd9-aae0-6f8a23291425",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fd35bb-4707-43a5-8c96-c7c3d70945f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load_testing_transformed_data(pickle_file_path, test_sub_id, fold_name):\n",
    "    \"\"\"\n",
    "    Load transformed data (x and y) for a specific test subject and fold.\n",
    "\n",
    "    Parameters:\n",
    "        pickle_file_path (str): Path to the saved pickle file.\n",
    "        test_sub_id (int): Subject index.\n",
    "        fold_name (str): Fold identifier, e.g., 'Fold1' or 'Fold2'.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with keys 'x' and 'y' for the requested subject and fold.\n",
    "    \"\"\"\n",
    "    with open(pickle_file_path, 'rb') as f:\n",
    "        transformed_data = pickle.load(f)\n",
    "\n",
    "    try:\n",
    "        subject_data = transformed_data[test_sub_id][fold_name]\n",
    "        return {\n",
    "            'x': subject_data['x'],\n",
    "            'y': subject_data['y']\n",
    "        }\n",
    "    except KeyError as e:\n",
    "        raise ValueError(f\"Invalid key: {e}. Check if subject ID and fold name are correct.\")\n",
    "\n",
    "# Example usage:\n",
    "# result = load_transformed_data(\"TransformedTesting.pkl\", test_sub_id=0, fold_name='Fold1')\n",
    "# X, Y = result['x'], result['y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ca3356-1cbd-4767-9b33-a623d2284003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load_training_transformed_data(pickle_file_path, test_sub_id):\n",
    "    \"\"\"\n",
    "    Load transformed data (x and y) for a specific test subject.\n",
    "\n",
    "    Parameters:\n",
    "        pickle_file_path (str): Path to the saved pickle file.\n",
    "        test_sub_id (int): Subject index.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with keys 'x' and 'y' for the requested subject.\n",
    "    \"\"\"\n",
    "    with open(pickle_file_path, 'rb') as f:\n",
    "        transformed_data = pickle.load(f)\n",
    "\n",
    "    try:\n",
    "        subject_data = transformed_data[test_sub_id]\n",
    "        return {\n",
    "            'x': subject_data['x'],\n",
    "            'y': subject_data['y']\n",
    "        }\n",
    "    except KeyError as e:\n",
    "        raise ValueError(f\"Invalid subject ID: {e}. Check if subject ID is correct.\")\n",
    "\n",
    "# Example usage:\n",
    "# result = load_transformed_data(\"TransformedTesting.pkl\", test_sub_id=0)\n",
    "# X, Y = result['x'], result['y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb48b856-8076-4b9f-840d-c1b7cf2ce29c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def SVM_UnCalibrated_Classification(XTrain, XTest, YTrain, YTest):\n",
    "    \n",
    "    SVM = SVC(C=1.0, kernel='linear', probability=True)\n",
    "    \n",
    "    SVM.fit(XTrain, YTrain)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = SVM.predict(XTest)\n",
    "    y_prob_uncalibrated = SVM.predict_proba(XTest)[:, 1]\n",
    "\n",
    "    #Calibration curve\n",
    "    calib_x = np.linspace(0.05, 0.95, 10)\n",
    "    prob_true_uncal, prob_pred_uncal = calibration_curve(YTest, y_prob_uncalibrated, n_bins=10)\n",
    "\n",
    "    interp_true_uncal = np.interp(calib_x, prob_pred_uncal, prob_true_uncal, left=np.nan, right=np.nan)\n",
    "\n",
    "    # Compute performance metrics\n",
    "    accuracy = accuracy_score(YTest, y_pred) \n",
    "    recall = recall_score(YTest,y_pred) \n",
    "    precision = precision_score(YTest, y_pred) \n",
    "    f1 = f1_score(YTest, y_pred) \n",
    "    brier = brier_score_loss(YTest, y_prob_uncalibrated)\n",
    "    \n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"recall\": recall,\n",
    "        \"precision\": precision,\n",
    "        \"f1_score\": f1,\n",
    "        \"brier_score\": brier,\n",
    "        \"calib_curve_pred\": calib_x,\n",
    "        \"calib_curve_true\": interp_true_uncal\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a9a2d9d-3c05-4f74-a224-d0e06636b3b1",
   "metadata": {
    "tags": []
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.frozen import FrozenEstimator\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def SVM_Calibrated_Classification(XTrain, XTest, YTrain, YTest):\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "    \n",
    "    Metrics_Fold = []\n",
    "    \n",
    "    for train_idx, test_idx in skf.split(XTest, YTest):\n",
    "        \n",
    "        # Split YTest and YTrain into 'calibration' and testing datasets\n",
    "        X_calib, X_final_test = XTest[train_idx], XTest[test_idx]\n",
    "        Y_calib, Y_final_test = YTest[train_idx], YTest[test_idx]\n",
    "    \n",
    "        base_SVM = SVC(C=1.0, kernel='linear')\n",
    "    \n",
    "        base_SVM.fit(XTrain, YTrain)\n",
    "    \n",
    "        # Calibrate classifier \n",
    "        calibrated_SVM = CalibratedClassifierCV(FrozenEstimator(base_SVM))\n",
    "        # Fit onto calibration dataset\n",
    "        calibrated_SVM.fit(X_calib, Y_calib)\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred = calibrated_SVM.predict(X_final_test)\n",
    "\n",
    "        # Compute performance metrics\n",
    "        accuracy = accuracy_score(Y_final_test, y_pred) \n",
    "        recall = recall_score(Y_final_test,y_pred) \n",
    "        precision = precision_score(Y_final_test, y_pred) \n",
    "        f1 = f1_score(Y_final_test, y_pred) \n",
    "    \n",
    "        metrics = {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"recall\": recall,\n",
    "            \"precision\": precision,\n",
    "            \"f1_score\": f1,\n",
    "        }\n",
    "        \n",
    "        Metrics_Fold.append(metrics)\n",
    "\n",
    "    return Metrics_Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9e021c-5e00-4554-99a2-e9d36db680d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.frozen import FrozenEstimator\n",
    "from sklearn.metrics import brier_score_loss\n",
    "import numpy as np\n",
    "\n",
    "def SVM_Calibrated_Classification(XTrain, XTest, YTrain, YTest):\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Lists to collect metrics per fold\n",
    "    accuracy_list = []\n",
    "    recall_list = []\n",
    "    precision_list = []\n",
    "    f1_list = []\n",
    "    brier_list = []\n",
    "    prob_true_all = []\n",
    "\n",
    "    calib_x = np.linspace(0.05, 0.95, 10)  # Common bin centers for interpolation\n",
    "\n",
    "    for fold_idx, (calib_idx, final_test_idx) in enumerate(skf.split(XTest, YTest)):\n",
    "        \n",
    "        # Split calibration and final test set\n",
    "        X_calib, X_final_test = XTest[calib_idx], XTest[final_test_idx]\n",
    "        Y_calib, Y_final_test = YTest[calib_idx], YTest[final_test_idx]\n",
    "    \n",
    "        # Base SVM\n",
    "        base_SVM = SVC(C=1.0, kernel='linear', probability=True)  \n",
    "        base_SVM.fit(XTrain, YTrain)\n",
    "    \n",
    "        # Calibrated SVM\n",
    "        calibrated_SVM = CalibratedClassifierCV(FrozenEstimator(base_SVM))\n",
    "        calibrated_SVM.fit(X_calib, Y_calib)\n",
    "\n",
    "        # Predictions\n",
    "        y_pred = calibrated_SVM.predict(X_final_test)\n",
    "        y_prob = calibrated_SVM.predict_proba(X_final_test)[:, 1]\n",
    "\n",
    "        # Metrics\n",
    "        accuracy_list.append(accuracy_score(Y_final_test, y_pred))\n",
    "        recall_list.append(recall_score(Y_final_test, y_pred))\n",
    "        precision_list.append(precision_score(Y_final_test, y_pred))\n",
    "        f1_list.append(f1_score(Y_final_test, y_pred))\n",
    "        brier_list.append(brier_score_loss(Y_final_test, y_prob))\n",
    "\n",
    "        # Calibration curve\n",
    "        prob_true, prob_pred = calibration_curve(Y_final_test, y_prob, n_bins=10)\n",
    "        interp_true = np.interp(calib_x, prob_pred, prob_true, left=np.nan, right=np.nan)\n",
    "        prob_true_all.append(interp_true)\n",
    "\n",
    "    # Average across folds\n",
    "    prob_true_avg = np.nanmean(prob_true_all, axis=0)\n",
    "\n",
    "    Metrics_Fold = {\n",
    "        \"accuracy\": np.mean(accuracy_list),\n",
    "        \"recall\": np.mean(recall_list),\n",
    "        \"precision\": np.mean(precision_list),\n",
    "        \"f1_score\": np.mean(f1_list),\n",
    "        \"brier_score\": np.mean(brier_list),\n",
    "        \"calib_curve_pred\": calib_x,\n",
    "        \"calib_curve_true\": prob_true_avg\n",
    "    }\n",
    "\n",
    "    return Metrics_Fold\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c3541974-8462-4b3d-b3e1-5ac0bec90b91",
   "metadata": {
    "tags": []
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.frozen import FrozenEstimator\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "\n",
    "\n",
    "def SVM_Calibrated_Classification_Explore(XTrain, XTest, YTrain, YTest, calib_ratio=0.5, n_repeats=5):\n",
    "    \n",
    "    Metrics_Fold = []\n",
    "\n",
    "    accuracy_list = []\n",
    "    recall_list = []\n",
    "    precision_list = []\n",
    "    f1_list = []\n",
    "\n",
    "    brier_list = []\n",
    "\n",
    "    calib_x = np.linspace(0.05, 0.95, 10)  # Common bin centers\n",
    "    prob_true_all = []\n",
    "    prob_pred_all = []\n",
    "    \n",
    "    for i in range(n_repeats): # Number of times to randomly split test into calibration and final testing\n",
    "        \n",
    "        # Stratified split of test data into calibration and final test sets - using split ration set in calib_ratio\n",
    "        X_calib, X_final_test, Y_calib, Y_final_test = train_test_split(\n",
    "            XTest, YTest,\n",
    "            train_size=calib_ratio,\n",
    "            stratify=YTest,\n",
    "            random_state=42 + i  # Different random state per repeat\n",
    "        )\n",
    "    \n",
    "        base_SVM = SVC(C=1.0, kernel='linear')\n",
    "    \n",
    "        base_SVM.fit(XTrain, YTrain)\n",
    "    \n",
    "        # Calibrate classifier \n",
    "        calibrated_SVM = CalibratedClassifierCV(FrozenEstimator(base_SVM))\n",
    "        # Fit onto calibration dataset\n",
    "        calibrated_SVM.fit(X_calib, Y_calib)\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred = calibrated_SVM.predict(X_final_test)\n",
    "        y_prob = calibrated_SVM.predict_proba(X_final_test)[:, 1]\n",
    "\n",
    "        # Compute performance metrics\n",
    "        accuracy_list.append(accuracy_score(Y_final_test, y_pred))\n",
    "        recall_list.append(recall_score(Y_final_test, y_pred))\n",
    "        precision_list.append(precision_score(Y_final_test, y_pred))\n",
    "        f1_list.append(f1_score(Y_final_test, y_pred))\n",
    "\n",
    "        brier_list.append(brier_score_loss(Y_final_test, y_prob))\n",
    "\n",
    "        # Calibration curve\n",
    "        prob_true, prob_pred = calibration_curve(Y_final_test, y_prob, n_bins=10, strategy='uniform')\n",
    "        # Interpolate onto common bin centers\n",
    "        interp_true = np.interp(calib_x, prob_pred, prob_true, left=np.nan, right=np.nan)\n",
    "        prob_true_all.append(interp_true)\n",
    "\n",
    "    prob_true_avg = np.nanmean(prob_true_all, axis=0)\n",
    "    \n",
    "    Metrics_Fold = {\n",
    "        \"accuracy\": np.mean(accuracy_list),\n",
    "        \"recall\": np.mean(recall_list),\n",
    "        \"precision\": np.mean(precision_list),\n",
    "        \"f1_score\": np.mean(f1_list),\n",
    "        \"brier_score\": np.mean(brier_list),\n",
    "        \"calib_curve_pred\": calib_x,\n",
    "        \"calib_curve_true\": prob_true_avg\n",
    "    }\n",
    "        \n",
    "\n",
    "    return Metrics_Fold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c351c456-397b-4352-9867-8e12d53ed810",
   "metadata": {},
   "source": [
    "# Load transformed training and testing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9ab639-2f5e-431f-8522-c55f679ee653",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import (transformed) training and testing features - baseline and spatially filtered \n",
    "Baseline_Path = '/home/nicole/Documents/AudioCueWalking_analysis/Variables/AdaptVsNon/LOSO_CV/Dataset/Ns_100_Individual/Advance/Transformed/Ind_TS_Transformed/Baseline'\n",
    "SpatFilt_Path = '/home/nicole/Documents/AudioCueWalking_analysis/Variables/AdaptVsNon/LOSO_CV/Dataset/Ns_100_Individual/Advance/Transformed/Ind_TS_Transformed/SpatFiltSignals'\n",
    "\n",
    "\n",
    "Baseline_Training_Path  = os.path.join(Baseline_Path, 'TransformedTraining.pkl')\n",
    "Baseline_Testing_Path = os.path.join(Baseline_Path, 'TransformedTesting.pkl')\n",
    "\n",
    "\n",
    "SpatFilt_Training_Path = os.path.join(SpatFilt_Path, 'TransformedTraining.pkl')\n",
    "SpatFilt_Testing_Path = os.path.join(SpatFilt_Path, 'TransformedTesting.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b970d90-6ce6-4544-9237-3b3d785c7cef",
   "metadata": {},
   "source": [
    "# Implement classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b47129d-c953-495a-8c69-4223237eb8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_ids = [0]\n",
    "#fold_names = ['Fold1', 'Fold2']\n",
    "fold_names = ['Fold1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6877594-30ca-47de-8301-5b87a74c0800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress specific FutureWarning\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*force_all_finite.*\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"The `cv='prefit'` option is deprecated\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "74712ac9-5893-4ca2-b74b-b1a67c6ee9a8",
   "metadata": {},
   "source": [
    "Results = {}\n",
    "\n",
    "splits = [0.3, 0.5] \n",
    "\n",
    "for test_sub_id in sub_ids:\n",
    "    print(f\"Classification for Subject {test_sub_id}...\")\n",
    "    Results[test_sub_id] = {}\n",
    "    \n",
    "    for fold_name in fold_names:\n",
    "        print(f\"\\nSubject {test_sub_id}, {fold_name} classification...\")\n",
    "        # ------- Load subject features -------\n",
    "        Baseline_Training = load_training_transformed_data(Baseline_Training_Path, test_sub_id)\n",
    "        Baseline_Testing = load_testing_transformed_data(Baseline_Testing_Path, test_sub_id, fold_name)\n",
    "\n",
    "        SpatFilt_Training = load_training_transformed_data(SpatFilt_Training_Path, test_sub_id)\n",
    "        SpatFilt_Testing = load_testing_transformed_data(SpatFilt_Testing_Path, test_sub_id, fold_name)\n",
    "        \n",
    "        # Load labels \n",
    "        Y_Train_Baseline = Baseline_Training['y']\n",
    "        Y_Train_SpatFilt = SpatFilt_Training['y']\n",
    "\n",
    "        Y_Test_Baseline = Baseline_Testing['y']\n",
    "        Y_Test_SpatFilt = SpatFilt_Testing['y']\n",
    "    \n",
    "        #Ensure labels are the same and assign baseline as labels \n",
    "        if np.array_equal(Y_Train_Baseline, Y_Train_SpatFilt) and np.array_equal(Y_Test_Baseline, Y_Test_SpatFilt):\n",
    "\n",
    "            Y_train_dataset = Y_Train_Baseline\n",
    "            Y_test_dataset = Y_Test_Baseline\n",
    "\n",
    "        else:\n",
    "\n",
    "            print(\"Labels do not match\")\n",
    "            sys.exit() \n",
    "        \n",
    "        # Load dataset\n",
    "        Baseline_Training_data = Baseline_Training['x']\n",
    "        Baseline_Testing_data = Baseline_Testing['x']\n",
    "\n",
    "        SpatFilt_Training_data = SpatFilt_Training['x']\n",
    "        SpatFilt_Testing_data = SpatFilt_Testing['x']\n",
    "\n",
    "        # Sanity Check \n",
    "        print(\"Loaded sizes: \")\n",
    "        print(\"Baseline training and testing: \")\n",
    "        print(Baseline_Training_data.shape)\n",
    "        print(Baseline_Testing_data.shape)\n",
    "        \n",
    "        print(\"SpatFilt training and testing: \")\n",
    "        print(SpatFilt_Training_data.shape)\n",
    "        print(SpatFilt_Testing_data.shape)\n",
    "        \n",
    "        \n",
    "        print(\"Labels training and testing: \")\n",
    "        print(Y_train_dataset.shape)\n",
    "        print(Y_test_dataset.shape)\n",
    "\n",
    "        Results[test_sub_id][fold_name] = {}\n",
    "\n",
    "    \n",
    "        # ------- Classify Spatially Filtered (RCSP(A) + Rie) -------\n",
    "        # print(\"SpatFilt classification\")\n",
    "        #Results[test_sub_id][fold_name][\"SpatFilt\"] = {}\n",
    "        # for ratio in splits:\n",
    "\n",
    "        #     print(f\"\\nEvaluating with calibration ratio: {ratio}\")\n",
    "            \n",
    "        #     SpatFilt_metrics = SVM_Calibrated_Classification_Explore(SpatFilt_Training_data, SpatFilt_Testing_data,  \n",
    "        #                                             Y_train_dataset, Y_test_dataset, \n",
    "        #                                             calib_ratio=ratio, n_repeats=5)\n",
    "\n",
    "            \n",
    "        #     print(f\"SpatFilt Metrics for test subject {test_sub_id} for fold {fold_name}:\")\n",
    "        #     print(SpatFilt_metrics)\n",
    "            \n",
    "        #     Results[test_sub_id][fold_name][\"SpatFilt\"][ratio] = SpatFilt_metrics\n",
    "        \n",
    "        #     del SpatFilt_metrics\n",
    "\n",
    "        \n",
    "        # ------- Create concatenated features Baseline + SpatFilt (per subject) -------\n",
    "        Baseline_Train_cat = np.concatenate((SpatFilt_Training_data, Baseline_Training_data), axis=1) #W/out cluster\n",
    "        Baseline_Test_cat = np.concatenate((SpatFilt_Testing_data, Baseline_Testing_data), axis=1)\n",
    "\n",
    "\n",
    "        # ------- Classify concatenation -------\n",
    "        print(\"Concat classification\")\n",
    "        Results[test_sub_id][fold_name][\"Concat\"] = {}\n",
    "        for ratio in splits:\n",
    "\n",
    "            print(f\"\\nEvaluating with calibration ratio: {ratio}\")\n",
    "            \n",
    "            Concat_metrics = SVM_Calibrated_Classification_Explore(Baseline_Train_cat , Baseline_Test_cat, \n",
    "                                                    Y_train_dataset, Y_test_dataset, \n",
    "                                                    calib_ratio=ratio, n_repeats=5)\n",
    "\n",
    "            \n",
    "            print(f\"Concat Metrics for test subject {test_sub_id} for fold {fold_name}:\")\n",
    "            print(Concat_metrics)\n",
    "            \n",
    "            Results[test_sub_id][fold_name][\"Concat\"][ratio] = Concat_metrics\n",
    "        \n",
    "            del Concat_metrics\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        del Baseline_Training_data , Baseline_Testing_data\n",
    "        del SpatFilt_Training_data, SpatFilt_Testing_data\n",
    "        del Baseline_Train_cat, Baseline_Test_cat\n",
    "        gc.collect()\n",
    "    \n",
    "        print(f\"Cleared variables for test subject {test_sub_id} for fold {fold_name}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "78e4e797-17e6-4add-b296-9541396b553e",
   "metadata": {},
   "source": [
    "with open('Results_Concat_Fold2.pkl', 'wb') as f:\n",
    "    pickle.dump(Results, f)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea2ad3a3-2f72-496f-81f1-0f5f2d453ff3",
   "metadata": {},
   "source": [
    "with open('Results_Concat_Fold2.pkl', 'rb') as f:\n",
    "    Results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b0c7820c-95bd-4a44-aa22-9e0e5a421661",
   "metadata": {},
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7f02573e-79d0-48e4-8817-a05f6c841613",
   "metadata": {},
   "source": [
    "splits = [0.7] \n",
    "\n",
    "for test_sub_id in sub_ids:\n",
    "    print(f\"Classification for Subject {test_sub_id}...\")\n",
    "    #Results[test_sub_id] = {}\n",
    "    \n",
    "    for fold_name in fold_names:\n",
    "        print(f\"\\nSubject {test_sub_id}, {fold_name} classification...\")\n",
    "        # ------- Load subject features -------\n",
    "        Baseline_Training = load_training_transformed_data(Baseline_Training_Path, test_sub_id)\n",
    "        Baseline_Testing = load_testing_transformed_data(Baseline_Testing_Path, test_sub_id, fold_name)\n",
    "\n",
    "        SpatFilt_Training = load_training_transformed_data(SpatFilt_Training_Path, test_sub_id)\n",
    "        SpatFilt_Testing = load_testing_transformed_data(SpatFilt_Testing_Path, test_sub_id, fold_name)\n",
    "        \n",
    "        # Load labels \n",
    "        Y_Train_Baseline = Baseline_Training['y']\n",
    "        Y_Train_SpatFilt = SpatFilt_Training['y']\n",
    "\n",
    "        Y_Test_Baseline = Baseline_Testing['y']\n",
    "        Y_Test_SpatFilt = SpatFilt_Testing['y']\n",
    "    \n",
    "        #Ensure labels are the same and assign baseline as labels \n",
    "        if np.array_equal(Y_Train_Baseline, Y_Train_SpatFilt) and np.array_equal(Y_Test_Baseline, Y_Test_SpatFilt):\n",
    "\n",
    "            Y_train_dataset = Y_Train_Baseline\n",
    "            Y_test_dataset = Y_Test_Baseline\n",
    "\n",
    "        else:\n",
    "\n",
    "            print(\"Labels do not match\")\n",
    "            sys.exit() \n",
    "        \n",
    "        # Load dataset\n",
    "        Baseline_Training_data = Baseline_Training['x']\n",
    "        Baseline_Testing_data = Baseline_Testing['x']\n",
    "\n",
    "        SpatFilt_Training_data = SpatFilt_Training['x']\n",
    "        SpatFilt_Testing_data = SpatFilt_Testing['x']\n",
    "\n",
    "        # Sanity Check \n",
    "        print(\"Loaded sizes: \")\n",
    "        print(\"Baseline training and testing: \")\n",
    "        print(Baseline_Training_data.shape)\n",
    "        print(Baseline_Testing_data.shape)\n",
    "        \n",
    "        print(\"SpatFilt training and testing: \")\n",
    "        print(SpatFilt_Training_data.shape)\n",
    "        print(SpatFilt_Testing_data.shape)\n",
    "        \n",
    "        \n",
    "        print(\"Labels training and testing: \")\n",
    "        print(Y_train_dataset.shape)\n",
    "        print(Y_test_dataset.shape)\n",
    "\n",
    "        #Results[test_sub_id][fold_name] = {}\n",
    "\n",
    "    \n",
    "        # ------- Classify Spatially Filtered (RCSP(A) + Rie) -------\n",
    "        # print(\"SpatFilt classification\")\n",
    "        #Results[test_sub_id][fold_name][\"SpatFilt\"] = {}\n",
    "        # for ratio in splits:\n",
    "\n",
    "        #     print(f\"\\nEvaluating with calibration ratio: {ratio}\")\n",
    "            \n",
    "        #     SpatFilt_metrics = SVM_Calibrated_Classification_Explore(SpatFilt_Training_data, SpatFilt_Testing_data,  \n",
    "        #                                             Y_train_dataset, Y_test_dataset, \n",
    "        #                                             calib_ratio=ratio, n_repeats=5)\n",
    "\n",
    "            \n",
    "        #     print(f\"SpatFilt Metrics for test subject {test_sub_id} for fold {fold_name}:\")\n",
    "        #     print(SpatFilt_metrics)\n",
    "            \n",
    "        #     Results[test_sub_id][fold_name][\"SpatFilt\"][ratio] = SpatFilt_metrics\n",
    "        \n",
    "        #     del SpatFilt_metrics\n",
    "\n",
    "        \n",
    "        # ------- Create concatenated features Baseline + SpatFilt (per subject) -------\n",
    "        Baseline_Train_cat = np.concatenate((SpatFilt_Training_data, Baseline_Training_data), axis=1) #W/out cluster\n",
    "        Baseline_Test_cat = np.concatenate((SpatFilt_Testing_data, Baseline_Testing_data), axis=1)\n",
    "\n",
    "\n",
    "        # ------- Classify concatenation -------\n",
    "        print(\"Concat classification\")\n",
    "        #Results[test_sub_id][fold_name][\"Concat\"] = {}\n",
    "        for ratio in splits:\n",
    "\n",
    "            print(f\"\\nEvaluating with calibration ratio: {ratio}\")\n",
    "            \n",
    "            Concat_metrics = SVM_Calibrated_Classification_Explore(Baseline_Train_cat , Baseline_Test_cat, \n",
    "                                                    Y_train_dataset, Y_test_dataset, \n",
    "                                                    calib_ratio=ratio, n_repeats=5)\n",
    "\n",
    "            \n",
    "            print(f\"Concat Metrics for test subject {test_sub_id} for fold {fold_name}:\")\n",
    "            print(Concat_metrics)\n",
    "            \n",
    "            Results[test_sub_id][fold_name][\"Concat\"][ratio] = Concat_metrics\n",
    "        \n",
    "            del Concat_metrics\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        del Baseline_Training_data , Baseline_Testing_data\n",
    "        del SpatFilt_Training_data, SpatFilt_Testing_data\n",
    "        del Baseline_Train_cat, Baseline_Test_cat\n",
    "        gc.collect()\n",
    "    \n",
    "        print(f\"Cleared variables for test subject {test_sub_id} for fold {fold_name}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "71c39dfc-1931-47eb-aae1-115d2bd0ef16",
   "metadata": {},
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dcd46d-160c-49d6-a3ea-ca7224098d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Results = {}\n",
    "\n",
    "for test_sub_id in sub_ids:\n",
    "    print(f\"Classification for Subject {test_sub_id}...\")\n",
    "    Results[test_sub_id] = {}\n",
    "    \n",
    "    for fold_name in fold_names:\n",
    "        print(f\"\\nSubject {test_sub_id}, {fold_name} classification...\")\n",
    "        # ------- Load subject features -------\n",
    "        Baseline_Training = load_training_transformed_data(Baseline_Training_Path, test_sub_id)\n",
    "        Baseline_Testing = load_testing_transformed_data(Baseline_Testing_Path, test_sub_id, fold_name)\n",
    "\n",
    "        SpatFilt_Training = load_training_transformed_data(SpatFilt_Training_Path, test_sub_id)\n",
    "        SpatFilt_Testing = load_testing_transformed_data(SpatFilt_Testing_Path, test_sub_id, fold_name)\n",
    "        \n",
    "        # Load labels \n",
    "        Y_Train_Baseline = Baseline_Training['y']\n",
    "        Y_Train_SpatFilt = SpatFilt_Training['y']\n",
    "\n",
    "        Y_Test_Baseline = Baseline_Testing['y']\n",
    "        Y_Test_SpatFilt = SpatFilt_Testing['y']\n",
    "    \n",
    "        #Ensure labels are the same and assign baseline as labels \n",
    "        if np.array_equal(Y_Train_Baseline, Y_Train_SpatFilt) and np.array_equal(Y_Test_Baseline, Y_Test_SpatFilt):\n",
    "\n",
    "            Y_train_dataset = Y_Train_Baseline\n",
    "            Y_test_dataset = Y_Test_Baseline\n",
    "\n",
    "        else:\n",
    "\n",
    "            print(\"Labels do not match\")\n",
    "            sys.exit() \n",
    "        \n",
    "        # Load dataset\n",
    "        Baseline_Training_data = Baseline_Training['x']\n",
    "        Baseline_Testing_data = Baseline_Testing['x']\n",
    "\n",
    "        SpatFilt_Training_data = SpatFilt_Training['x']\n",
    "        SpatFilt_Testing_data = SpatFilt_Testing['x']\n",
    "\n",
    "        # Sanity Check \n",
    "        print(\"Loaded sizes: \")\n",
    "        print(\"Baseline training and testing: \")\n",
    "        print(Baseline_Training_data.shape)\n",
    "        print(Baseline_Testing_data.shape)\n",
    "        \n",
    "        print(\"SpatFilt training and testing: \")\n",
    "        print(SpatFilt_Training_data.shape)\n",
    "        print(SpatFilt_Testing_data.shape)\n",
    "        \n",
    "        \n",
    "        print(\"Labels training and testing: \")\n",
    "        print(Y_train_dataset.shape)\n",
    "        print(Y_test_dataset.shape)\n",
    "\n",
    "        Results[test_sub_id][fold_name] = {}\n",
    "\n",
    "        # ------- Classify baselines -------\n",
    "        # print(\"Baseline classification\")\n",
    "        # Baseline_metrics = SVM_Calibrated_Classification(Baseline_Training_data, Baseline_Testing_data, Y_train_dataset, Y_test_dataset)\n",
    "        # print(f\"Baseline Metrics for test subject {test_sub_id} for fold {fold_name}:\")\n",
    "        # print(Baseline_metrics)\n",
    "\n",
    "        # #Results[test_sub_id][fold_name][\"Baseline\"] = Baseline_metrics\n",
    "        # Results[test_sub_id][fold_name][\"Baseline\"] = {\n",
    "        #     \"Calib1\": Baseline_metrics[0],\n",
    "        #     \"Calib2\": Baseline_metrics[1]\n",
    "        #     }\n",
    "\n",
    "        # del Baseline_metrics \n",
    "        \n",
    "        # ------- Classify Spatially Filtered (RCSP(A) + Rie) -------\n",
    "        print(\"SpatFilt classification\")\n",
    "        SpatFilt_metrics = SVM_UnCalibrated_Classification(SpatFilt_Training_data, SpatFilt_Testing_data, Y_train_dataset, Y_test_dataset)\n",
    "        #SpatFilt_metrics = SVM_Calibrated_Classification(SpatFilt_Training_data, SpatFilt_Testing_data, Y_train_dataset, Y_test_dataset)\n",
    "\n",
    "        \n",
    "        \n",
    "        print(f\"SpatFilt Metrics for test subject {test_sub_id} for fold {fold_name}:\")\n",
    "        print(SpatFilt_metrics)\n",
    "        \n",
    "        Results[test_sub_id][fold_name][\"SpatFilt\"] = SpatFilt_metrics\n",
    "        # Results[test_sub_id][fold_name][\"SpatFilt\"] = {\n",
    "        #     \"Calib1\": SpatFilt_metrics[0],\n",
    "        #     \"Calib2\": SpatFilt_metrics[1]\n",
    "        #     }\n",
    "\n",
    "        del SpatFilt_metrics\n",
    "        \n",
    "        # ------- Create concatenated features Baseline + SpatFilt (per subject) -------\n",
    "        Baseline_Train_cat = np.concatenate((SpatFilt_Training_data, Baseline_Training_data), axis=1) #W/out cluster\n",
    "        Baseline_Test_cat = np.concatenate((SpatFilt_Testing_data, Baseline_Testing_data), axis=1)\n",
    "\n",
    "\n",
    "        # ------- Classify concatenation -------\n",
    "        print(\"Concat classification\")\n",
    "        Concat_metrics = SVM_UnCalibrated_Classification(Baseline_Train_cat , Baseline_Test_cat, Y_train_dataset, Y_test_dataset)\n",
    "        #Concat_metrics = SVM_Calibrated_Classification(Baseline_Train_cat , Baseline_Test_cat, Y_train_dataset, Y_test_dataset)\n",
    "        \n",
    "        print(f\"Concat Metrics for test subject {test_sub_id} for fold {fold_name}:\")\n",
    "        print(Concat_metrics)\n",
    "\n",
    "        Results[test_sub_id][fold_name][\"Concat\"] = Concat_metrics\n",
    "        # Results[test_sub_id][fold_name][\"Concat\"] = {\n",
    "        #     \"Calib1\": Concat_metrics[0],\n",
    "        #     \"Calib2\": Concat_metrics[1]\n",
    "        #     }\n",
    "        \n",
    "        \n",
    "        del Concat_metrics\n",
    "        \n",
    "        #del Baseline_Training_data , Baseline_Testing_data\n",
    "        del SpatFilt_Training_data, SpatFilt_Testing_data, Baseline_Train_cat, Baseline_Test_cat\n",
    "\n",
    "        #Save 'Results'\n",
    "        filename = f\"Results_Subject{test_sub_id}_{fold_name}_WCalibration.pkl\"\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(Results, f)\n",
    "        \n",
    "        gc.collect()\n",
    "    \n",
    "        print(f\"Cleared variables for test subject {test_sub_id} for fold {fold_name}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "581171d5-3599-4503-8374-bcd85195811b",
   "metadata": {
    "tags": []
   },
   "source": [
    "results = Results[sub_ids[0]][fold_names[0]]\n",
    "\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\n{model_name} results:\")\n",
    "    for calib_fold, calib_metrics in metrics.items():  # Iterate over \"Calib1\", \"Calib2\"\n",
    "        print(f\"  {calib_fold} results:\")\n",
    "        for metric_name, value in calib_metrics.items():\n",
    "            print(f\"    {value:.10f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0910c8cd-e4d5-4cc4-a7db-f36262b39366",
   "metadata": {},
   "source": [
    "# Finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3404666-f927-40ca-ae58-37f37c5a8280",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Elapsed time:\", elapsed_time/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ce8c07-c012-4650-be27-354847413abd",
   "metadata": {},
   "source": [
    "# Calibration Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab4336d-33be-45d3-888e-5dd10c11838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the three ratios you are interested in\n",
    "ratios = [0.3, 0.5, 0.7]\n",
    "colors = ['r', 'g', 'b']  # Red for 0.3, Green for 0.5, Blue for 0.7\n",
    "labels = ['30:70', '50:50', '70:30']  # Labels for the legend\n",
    "\n",
    "# Loop through the ratios\n",
    "for ratio, color, label in zip(ratios, colors, labels):\n",
    "    calib_curve_true = Results[test_sub_id][fold_name][\"Concat\"][ratio][\"calib_curve_true\"]\n",
    "    calib_curve_pred = Results[test_sub_id][fold_name][\"Concat\"][ratio][\"calib_curve_pred\"]\n",
    "    \n",
    "    # Plot the calibration curve for this ratio\n",
    "    plt.plot(calib_curve_pred, calib_curve_true, marker='o', color=color, label=label)\n",
    "\n",
    "# Ideal calibration line (diagonal line)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfect Calibration')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Mean predicted probability')\n",
    "plt.ylabel('Fraction of positives')\n",
    "plt.title(f'Calibration Curves for Test Subject {test_sub_id}, PS Fold: {fold_name}')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ca79ed8b-448d-4ac9-a128-af25a648e36d",
   "metadata": {},
   "source": [
    "cd '/home/nicole/Documents/AudioCueWalking_analysis/Python/PreAligmentStrategy/TangentSpace_IndividualRecentring_PS/Calibration_Results'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "28e9698b-2726-4385-8b08-50ac6f28b448",
   "metadata": {},
   "source": [
    "with open('Results_Subject0_Fold1_WoutCalibration.pkl', 'rb') as Wout_Fold1:\n",
    "    Wout_Fold1 = pickle.load(Wout_Fold1)\n",
    "    \n",
    "with open('Results_Subject0_Fold2_WoutCalibration.pkl', 'rb') as Wout_Fold2:\n",
    "    Wout_Fold2 = pickle.load(Wout_Fold2)\n",
    "\n",
    "with open('Results_Subject0_Fold1_WCalibration.pkl', 'rb') as W_Fold1:\n",
    "    W_Fold1 = pickle.load(W_Fold1)\n",
    "    \n",
    "with open('Results_Subject0_Fold2_WoutCalibration.pkl', 'rb') as W_Fold2:\n",
    "    W_Fold2 = pickle.load(W_Fold2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c951342-7d04-4a4f-a109-826b531d9a15",
   "metadata": {},
   "source": [
    "SigProcTech = 'Concat'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f0f6d671-25ed-42b2-9064-665d35c03528",
   "metadata": {},
   "source": [
    "W_BrierScore = np.mean([W_Fold1[0]['Fold1'][SigProcTech]['brier_score'], W_Fold2[0]['Fold2'][SigProcTech]['brier_score']])\n",
    "Wout_BrierScore = np.mean([Wout_Fold1[0]['Fold1'][SigProcTech]['brier_score'], Wout_Fold2[0]['Fold2'][SigProcTech]['brier_score']])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "64c7c7c6-085a-448d-a31f-69b88824f62d",
   "metadata": {},
   "source": [
    "calib_curve_pred = Wout_Fold1[0]['Fold1'][SigProcTech]['calib_curve_pred'] #Same for all folds and conditions "
   ]
  },
  {
   "cell_type": "raw",
   "id": "25d08ef2-1bad-4af0-bcbb-a99fb130b53a",
   "metadata": {},
   "source": [
    "W_calib_curve_true = np.mean([W_Fold1[0]['Fold1'][SigProcTech]['calib_curve_true'], W_Fold2[0]['Fold2'][SigProcTech]['calib_curve_true']], axis = 0)\n",
    "Wout_calib_curve_true = np.mean([Wout_Fold1[0]['Fold1'][SigProcTech]['calib_curve_true'], Wout_Fold2[0]['Fold2'][SigProcTech]['calib_curve_true']], axis = 0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "17a6663f-f8de-498f-a24d-26dd49bae33a",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the three ratios you are interested in\n",
    "colours = ['r', 'g'] \n",
    "labels = ['Uncalibrated', 'Calibrated - 50:50']  \n",
    "\n",
    "#Plot Uncalibrated\n",
    "plt.plot(\n",
    "    calib_curve_pred,\n",
    "    Wout_calib_curve_true,\n",
    "    marker='o',\n",
    "    color=colors[0],\n",
    "    label=f'Uncalibrated SVM (Brier={Wout_BrierScore:.3f})'\n",
    ")\n",
    "\n",
    "#Plot Calibrated\n",
    "plt.plot(\n",
    "    calib_curve_pred,\n",
    "    W_calib_curve_true,\n",
    "    marker='o',\n",
    "    color=colours[1],\n",
    "    label=f'Calibrated SVM (Brier={W_BrierScore:.3f})'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Ideal calibration line (diagonal line)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfect Calibration')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Mean predicted probability')\n",
    "plt.ylabel('Fraction of positives')\n",
    "plt.suptitle('Calibration Curves: Uncalibrated vs. Calibrated SVM - Subject 001, Advance Tempo')\n",
    "plt.title('Concatenated', fontsize = 12)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f889b5-c078-445e-8afd-f2fb29503519",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyRiemann_Py39",
   "language": "python",
   "name": "pyriemann_py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
