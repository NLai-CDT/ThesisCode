{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35d5daab-48bb-42b8-bb59-ac8a8b416c17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "\n",
    "patch_sklearn()\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.covariance import LedoitWolf\n",
    "\n",
    "from pyriemann.estimation import Covariances\n",
    "from pyriemann.classification import TSclassifier\n",
    "from pyriemann.spatialfilters import CSP\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "#from pyriemann.classification import SVC\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import h5py\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0ba7d84-6437-4e49-b147-c7c7212a8283",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ef27db0-d937-45d2-bd20-9092ce57aba8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LoadingPath_Non='/home/nicole/Documents/AudioCueWalking_analysis/Variables/AdaptVsNon/LOSO_CV/Dataset/Ns_100/Delay'\n",
    "LoadingPath_PS = '/home/nicole/Documents/AudioCueWalking_analysis/Variables/AdaptVsNon/LOSO_CV/Dataset/Ns_100/Delay/Transformed/IndividualSubjects_Adaptive/TrainingTestingDatasets'\n",
    "\n",
    "\n",
    "#PreAlignmentCondition = 'Yes'\n",
    "subject_ids = [0, 1] \n",
    "#subject_ids = [9, 10, 11, 12, 13, 14, 15, 16, 17] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "120fabe7-6048-4da4-9c48-8b273534a54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nc = 108"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32efc0a-ae05-4e54-b0aa-2d0c0be5aa10",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4aa6d3be-8846-4717-ab33-3c643777d19c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "def load_subject_data(loading_path, subject_id, n_components=108, PreAlignment='No'):\n",
    "    \"\"\"\n",
    "    Load (raw or prealigned) training and testing datasets, projected datasets, and features for a given subject.\n",
    "    \n",
    "    Parameters:\n",
    "        loading_path (str): Path to the directory containing the dataset files.\n",
    "        subject_id (int): Subject ID (0-based index).\n",
    "        n_components (int): Number of components/features to extract.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary containing all loaded datasets and features.\n",
    "    \"\"\"\n",
    "    # File paths\n",
    "    if  PreAlignment == 'No':\n",
    "        training_dataset_path = os.path.join(loading_path, 'TrainingDataset.mat')\n",
    "        testing_dataset_path = os.path.join(loading_path, 'TestingDataset.mat') \n",
    "        training_projected_path = os.path.join(loading_path, 'TrainingProjected_sub001_002.mat')\n",
    "        testing_projected_path = os.path.join(loading_path, 'TestingProjected_sub001_002.mat')\n",
    "        training_features_path = os.path.join(loading_path, 'TrainingFeatures.mat')\n",
    "        testing_features_path = os.path.join(loading_path, 'TestingFeatures.mat')\n",
    "    elif PreAlignment == 'Yes':\n",
    "        training_dataset_path = os.path.join(loading_path, 'TrainingDataset_sub001_002.mat')\n",
    "        testing_dataset_path = os.path.join(loading_path, 'TestingDataset.mat') \n",
    "        training_projected_path = os.path.join(loading_path, 'TrainingProjected_sub001_002.mat')\n",
    "        testing_projected_path = os.path.join(loading_path, 'TestingProjected_sub001_002.mat')\n",
    "        training_features_path = os.path.join(loading_path, 'TrainingFeatures_sub001_002.mat')\n",
    "        testing_features_path = os.path.join(loading_path, 'TestingFeatures_sub001_002.mat')\n",
    "\n",
    "    # Load Training Dataset\n",
    "    with h5py.File(training_dataset_path, 'r') as f_training_dataset:\n",
    "        training_dataset = f_training_dataset['TrainingDataset']\n",
    "        subject_cell_ref = training_dataset[subject_id, 0]\n",
    "        subject_data = f_training_dataset[subject_cell_ref]\n",
    "        X_train_dataset = np.transpose(subject_data['x'][:], (0, 1, 2))\n",
    "        Y_train_dataset = np.squeeze(subject_data['y'][:])\n",
    "\n",
    "    # Load Testing Dataset\n",
    "    if  PreAlignment == 'No':\n",
    "        # Advance\n",
    "        # f_testing_dataset = scipy.io.loadmat(testing_dataset_path)\n",
    "        # testing_dataset = f_testing_dataset['TestingDataset'][0, subject_id]\n",
    "        # X_test_dataset = np.transpose(np.array(testing_dataset['x'][0][0]), (2, 1, 0))\n",
    "        # #X_test_dataset = np.abs(X_test_dataset) #Added pre-aligment data is complex\n",
    "        # Y_test_dataset = np.squeeze(np.array(testing_dataset['y'][0][0]))\n",
    "        \n",
    "        #Delay\n",
    "        with h5py.File(testing_dataset_path, 'r') as f_testing_dataset:\n",
    "            testing_dataset = f_testing_dataset['TestingDataset']\n",
    "            subject_cell_ref = testing_dataset[subject_id, 0]\n",
    "            subject_data = f_testing_dataset[subject_cell_ref]\n",
    "            X_test_dataset = np.transpose(subject_data['x'][:], (0, 1, 2))\n",
    "            Y_test_dataset = np.squeeze(subject_data['y'][:])\n",
    "\n",
    "    elif PreAlignment == 'Yes':\n",
    "        with h5py.File(testing_dataset_path, 'r') as f_testing_dataset:\n",
    "            testing_dataset = f_testing_dataset['TestingDataset']\n",
    "            subject_cell_ref = testing_dataset[subject_id, 0]\n",
    "            subject_data = f_testing_dataset[subject_cell_ref]\n",
    "            X_test_dataset = np.transpose(subject_data['x'][:], (0, 1, 2))\n",
    "            Y_test_dataset = np.squeeze(subject_data['y'][:])\n",
    "\n",
    "\n",
    "    # Load Training Projected Dataset\n",
    "    with h5py.File(training_projected_path, 'r') as f_training_projected:\n",
    "        training_projected = f_training_projected['TrainingProjected']\n",
    "        subject_cell_ref = training_projected[subject_id, 0]\n",
    "        subject_data = f_training_projected[subject_cell_ref]\n",
    "        X_train_projected = np.transpose(subject_data['x'][:], (0, 2, 1))\n",
    "        Y_train_projected = np.squeeze(subject_data['y'][:])\n",
    "\n",
    "    # Load Testing Projected Dataset\n",
    "    if  PreAlignment == 'No':\n",
    "        #Advance\n",
    "        # f_testing_projected = scipy.io.loadmat(testing_projected_path)\n",
    "        # testing_projected = f_testing_projected['TestingProjected'][0, subject_id]\n",
    "        # X_test_projected = np.transpose(np.array(testing_projected['x'][0][0]), (2, 0, 1))\n",
    "        # #X_test_projected = np.abs(X_test_projected) #Added pre-aligment data is complex\n",
    "        # Y_test_projected = np.squeeze(np.array(testing_projected['y'][0][0]))\n",
    "        \n",
    "        #Delay\n",
    "        with h5py.File(testing_projected_path, 'r') as f_testing_projected:\n",
    "            testing_projected = f_testing_projected['TestingProjected']\n",
    "            subject_cell_ref = testing_projected[subject_id, 0]\n",
    "            subject_data = f_testing_projected[subject_cell_ref]\n",
    "            X_test_projected = np.transpose(subject_data['x'][:], (0, 2, 1))\n",
    "            Y_test_projected = np.squeeze(subject_data['y'][:])\n",
    "            \n",
    "    elif PreAlignment == 'Yes':\n",
    "        with h5py.File(testing_projected_path, 'r') as f_testing_projected:\n",
    "            testing_projected = f_testing_projected['TestingProjected']\n",
    "            subject_cell_ref = testing_projected[subject_id, 0]\n",
    "            subject_data = f_testing_projected[subject_cell_ref]\n",
    "            X_test_projected = np.transpose(subject_data['x'][:], (0, 2, 1))\n",
    "            Y_test_projected = np.squeeze(subject_data['y'][:])\n",
    "\n",
    "    # Load Training Features\n",
    "    f_training_features = scipy.io.loadmat(training_features_path)\n",
    "    training_features = f_training_features['TrainingFeatures'][0, subject_id]\n",
    "    X_train_features = training_features[:, :n_components]\n",
    "    Y_train_features = training_features[:, n_components:].flatten()\n",
    "\n",
    "    # Load Testing Features\n",
    "    f_testing_features = scipy.io.loadmat(testing_features_path)\n",
    "    testing_features = f_testing_features['TestingFeatures'][0, subject_id]\n",
    "    X_test_features = testing_features[:, :n_components]\n",
    "    Y_test_features = testing_features[:, n_components:].flatten()\n",
    "\n",
    "    # Organize results into a dictionary\n",
    "    data = {\n",
    "        \"X_train_dataset\": X_train_dataset,\n",
    "        \"Y_train_dataset\": Y_train_dataset,\n",
    "        \"X_test_dataset\": X_test_dataset,\n",
    "        \"Y_test_dataset\": Y_test_dataset,\n",
    "        \"X_train_projected\": X_train_projected,\n",
    "        \"Y_train_projected\": Y_train_projected,\n",
    "        \"X_test_projected\": X_test_projected,\n",
    "        \"Y_test_projected\": Y_test_projected,\n",
    "        \"X_train_features\": X_train_features,\n",
    "        \"Y_train_features\": Y_train_features,\n",
    "        \"X_test_features\": X_test_features,\n",
    "        \"Y_test_features\": Y_test_features,\n",
    "    }\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91c721b-149e-4200-85cf-87e0e262a5be",
   "metadata": {},
   "source": [
    "# Classification Algorithms "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dc68a8-81ab-4677-b846-f2ef0ae58ba7",
   "metadata": {},
   "source": [
    "## Riemannian Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59d152e9-a338-4913-8696-9f44fd9e3f56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def RiemannianGeometry(X_train_dataset, Y_train_dataset, X_test_dataset, Y_test_dataset, metric='riemann', C=1.0, kernel='linear'):\n",
    "    \"\"\"\n",
    "    Projects dataset onto TS and classifies\n",
    "\n",
    "    Parameters:\n",
    "        X_train (array): Training dataset features.\n",
    "        Y_train (array): Training dataset labels.\n",
    "        X_test (array): Testing dataset features.\n",
    "        Y_test (array): Testing dataset labels.\n",
    "        metric (str): Metric for the TSclassifier (default: 'riemann').\n",
    "        C (float): Regularization parameter for the SVM (default: 1.0).\n",
    "        kernel (str): Kernel type for the SVM (default: 'linear').\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the predicted labels and performance metrics (accuracy, recall, precision, F1 score).\n",
    "    \"\"\"\n",
    "    # Initialize the covariance estimator\n",
    "    cov_estimator = Covariances(estimator='lwf')  # Regularized covariance estimation\n",
    "\n",
    "    \n",
    "    # Transform training and testing datasets\n",
    "    X_train_cov = cov_estimator.transform(X_train_dataset)\n",
    "    X_test_cov = cov_estimator.transform(X_test_dataset)\n",
    "    \n",
    "    # Initialize the TSclassifier with an SVC\n",
    "    clf_TS = TSclassifier(metric=metric, clf=SVC(C=C, kernel=kernel))\n",
    "    \n",
    "    # Train the classifier\n",
    "    clf_TS.fit(X_train_cov, Y_train_dataset)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = clf_TS.predict(X_test_cov)\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    accuracy = accuracy_score(Y_test_dataset, y_pred) \n",
    "    recall = recall_score(Y_test_dataset, y_pred) \n",
    "    precision = precision_score(Y_test_dataset, y_pred) \n",
    "    f1 = f1_score(Y_test_dataset, y_pred) \n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"RieGeo A: {accuracy:.4f}%\")\n",
    "    print(f\"RieGeo R: {recall:.4f}%\")\n",
    "    print(f\"RieGeo P: {precision:.4f}%\")\n",
    "    print(f\"RieGeo F1: {f1:.4f}%\")\n",
    "    \n",
    "    # Organize results into a dictionary\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"recall\": recall,\n",
    "        \"precision\": precision,\n",
    "        \"f1_score\": f1,\n",
    "        #\"predictions\": y_pred,\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76720a82-b4e6-4e97-87c7-e0019bd82b20",
   "metadata": {},
   "source": [
    "## CSP: Arithmetic average \"Spatial filtered (A) + Riemann\"\n",
    "### Project spatially filtered signals (ProjectedDataset) to tangent space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9163482-c90a-4dfb-8406-43dc3697f474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SpatFilt_A_Rie(X_train_projected, Y_train_projected, X_test_projected, Y_test_dataset, metric='riemann', C=1.0, kernel='linear'):\n",
    "    \"\"\"\n",
    "    Projects spatially filtered (A) features onto TS and classifies\n",
    "    \n",
    "    Parameters:\n",
    "        X_train_projected (np.ndarray): Training data (projected).\n",
    "        Y_train_projected (np.ndarray): Training labels (projected).\n",
    "        X_test_projected (np.ndarray): Testing data (projected).\n",
    "        Y_test_dataset (np.ndarray): True labels for the testing data.\n",
    "        metric (str): Metric to use for the TSclassifier. Default is 'riemann'.\n",
    "        C (float): Regularization parameter for the SVM. Default is 1.0.\n",
    "        kernel (str): Kernel type for the SVM. Default is 'linear'.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing accuracy, recall, precision, and F1 score.\n",
    "    \"\"\"\n",
    "    # Estimate covariance matrices\n",
    "    cov_estimator_projected = Covariances(estimator='lwf')  # Helps with regularization\n",
    "    X_train_cov_projected = cov_estimator_projected.transform(X_train_projected)\n",
    "    X_test_cov_projected = cov_estimator_projected.transform(X_test_projected)\n",
    "\n",
    "    # Train the classifier\n",
    "    clf_TS_proj = TSclassifier(metric=metric, clf=SVC(C=C, kernel=kernel, class_weight='balanced'))\n",
    "    clf_TS_proj.fit(X_train_cov_projected, Y_train_projected)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred_proj = clf_TS_proj.predict(X_test_cov_projected)\n",
    "    \n",
    "    # Compute performance metrics\n",
    "    accuracy = accuracy_score(Y_test_dataset, y_pred_proj) \n",
    "    recall = recall_score(Y_test_dataset, y_pred_proj) \n",
    "    precision = precision_score(Y_test_dataset, y_pred_proj) \n",
    "    f1 = f1_score(Y_test_dataset, y_pred_proj) \n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"SpatFilt(A) + Rie A: {accuracy:.4f}%\")\n",
    "    print(f\"SpatFilt(A) + Rie R: {recall:.4f}%\")\n",
    "    print(f\"SpatFilt(A) + Rie P: {precision:.4f}%\")\n",
    "    print(f\"SpatFilt(A) + Rie F1: {f1:.4f}%\")\n",
    "\n",
    "    # Return metrics as a dictionary\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"recall\": recall,\n",
    "        \"precision\": precision,\n",
    "        \"f1_score\": f1,\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf5552f-03a0-4781-a71c-273137ab799c",
   "metadata": {},
   "source": [
    "## CSP: Riemannian average (1) \"CSP(R) + Riemann\"\n",
    "### Use pyriemann.spatialfilters.csp (TrainingDataset) to obtain spatially filtered signals, project and classify in tangent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50123648-2cfd-47a9-b952-36c834330950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CSP_R_Rie(X_train_dataset, Y_train_dataset, X_test_dataset, Y_test_dataset, \n",
    "                           nfilter=108, metric='riemann', log=False, C=1.0, kernel='linear'):\n",
    "    \"\"\"\n",
    "    Obtains CSP (using riemannian mean), spatially filters dataset, projects onto TS and classifies\n",
    "    \n",
    "    Parameters:\n",
    "        X_train_dataset (np.ndarray): Training data (raw).\n",
    "        Y_train_dataset (np.ndarray): Training labels.\n",
    "        X_test_dataset (np.ndarray): Testing data (raw).\n",
    "        Y_test_dataset (np.ndarray): True labels for the testing data.\n",
    "        nfilter (int): Number of filters for the CSP. Default is 4.\n",
    "        metric (str): Metric to use for the TSclassifier. Default is 'riemann'.\n",
    "        log (bool): Whether to apply log transformation in CSP. Default is False.\n",
    "        C (float): Regularization parameter for the SVM. Default is 1.0.\n",
    "        kernel (str): Kernel type for the SVM. Default is 'linear'.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing accuracy, recall, precision, and F1 score.\n",
    "    \"\"\"\n",
    "    # Covariance matrix estimation\n",
    "    cov_estimator = Covariances(estimator='lwf')\n",
    "    X_train_cov = cov_estimator.transform(X_train_dataset)\n",
    "    X_test_cov = cov_estimator.transform(X_test_dataset)\n",
    "\n",
    "    # CSP transformation\n",
    "    csp = CSP(nfilter=nfilter, metric=metric, log=log)\n",
    "    X_train_csp = csp.fit_transform(X_train_cov, Y_train_dataset)\n",
    "    X_test_csp = csp.transform(X_test_cov)\n",
    "\n",
    "    # Train the classifier\n",
    "    clf_TS_features = TSclassifier(metric=metric, clf=SVC(C=C, kernel=kernel, class_weight='balanced'))\n",
    "    clf_TS_features.fit(X_train_csp, Y_train_dataset)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred_features = clf_TS_features.predict(X_test_csp)\n",
    "    \n",
    "    \n",
    "    # Compute performance metrics\n",
    "    accuracy = accuracy_score(Y_test_dataset, y_pred_features) \n",
    "    recall = recall_score(Y_test_dataset, y_pred_features) \n",
    "    precision = precision_score(Y_test_dataset, y_pred_features) \n",
    "    f1 = f1_score(Y_test_dataset, y_pred_features) \n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"CSP(R) + Rie A: {accuracy:.4f}%\")\n",
    "    print(f\"CSP(R) + Rie R: {recall:.4f}%\")\n",
    "    print(f\"CSP(R) + Rie P: {precision:.4f}%\")\n",
    "    print(f\"CSP(R) + Rie F1: {f1:.4f}%\")\n",
    "\n",
    "    # Return metrics as a dictionary\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"recall\": recall,\n",
    "        \"precision\": precision,\n",
    "        \"f1_score\": f1,\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e99fe27-644d-49c0-bfa0-17a2ad1a4f5e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CSP: Concatenation of features \n",
    "### Concatenate CSP variance features and tangent space features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33e93858-46be-4ed3-bef0-e6eba55d559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Concat(X_train_dataset, Y_train_dataset, X_test_dataset, Y_test_dataset, \n",
    "                                    X_train_features, X_test_features, metric='riemann', C=1.0, kernel='linear'):\n",
    "    \"\"\"\n",
    "    Concatenates spatially filtered features and features found from TS projection of dataset and classfies\n",
    "    \n",
    "    Parameters:\n",
    "        X_train_dataset (np.ndarray): Training data (raw).\n",
    "        Y_train_dataset (np.ndarray): Training labels.\n",
    "        X_test_dataset (np.ndarray): Testing data (raw).\n",
    "        Y_test_dataset (np.ndarray): True labels for the testing data.\n",
    "        X_train_features (np.ndarray): Additional training features.\n",
    "        X_test_features (np.ndarray): Additional testing features.\n",
    "        metric (str): Metric to use for TangentSpace. Default is 'riemann'.\n",
    "        C (float): Regularization parameter for the SVM. Default is 1.0.\n",
    "        kernel (str): Kernel type for the SVM. Default is 'linear'.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing accuracy, recall, precision, and F1 score.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- Find tanget space features ---\n",
    "    # Covariance matrix estimation\n",
    "    cov_estimator = Covariances(estimator='lwf')  # Helps with regularization\n",
    "    X_train_cov = cov_estimator.transform(X_train_dataset)\n",
    "    X_test_cov = cov_estimator.transform(X_test_dataset)\n",
    "\n",
    "    # Tangent Space transformation\n",
    "    TSpace = TangentSpace(metric=metric, tsupdate=False).fit(X_train_cov)\n",
    "    X_train_TS = TSpace.transform(X_train_cov)\n",
    "    X_test_TS = TSpace.transform(X_test_cov)\n",
    "    \n",
    "    # --- Concatenate ---\n",
    "    # Combine features and Tangent Space data\n",
    "    X_train_cat = np.concatenate((X_train_features, X_train_TS), axis=1)\n",
    "    X_test_cat = np.concatenate((X_test_features, X_test_TS), axis=1)\n",
    "\n",
    "    # Train the classifier\n",
    "    clf_TS_cat = SVC(C=C, kernel=kernel, class_weight='balanced')\n",
    "    clf_TS_cat.fit(X_train_cat, Y_train_dataset)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred_cat = clf_TS_cat.predict(X_test_cat)\n",
    "    \n",
    "    # Compute performance metrics\n",
    "    accuracy = accuracy_score(Y_test_dataset, y_pred_cat) \n",
    "    recall = recall_score(Y_test_dataset,y_pred_cat) \n",
    "    precision = precision_score(Y_test_dataset, y_pred_cat) \n",
    "    f1 = f1_score(Y_test_dataset, y_pred_cat) \n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"Concat A: {accuracy:.4f}%\")\n",
    "    print(f\"Concat R: {recall:.4f}%\")\n",
    "    print(f\"Concat P: {precision:.4f}%\")\n",
    "    print(f\"Concat F1: {f1:.4f}%\")\n",
    "\n",
    "    \n",
    "    # Return metrics as a dictionary\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"recall\": recall,\n",
    "        \"precision\": precision,\n",
    "        \"f1_score\": f1,\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1979194a-6cf7-4b75-aeff-1e72ee3ed3b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Implement functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a990c84f-790f-4ddc-a799-5ce0d2591646",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/nicole/Documents/AudioCueWalking_analysis/Variables/AdaptVsNon/LOSO_CV/Dataset/Ns_100/Delay/Transformed/IndividualSubjects_Adaptive/TrainingTestingDatasets with PreAlignmentCondition = Yes\n",
      "Loading data for Subject 0...\n",
      "(50538, 108, 100)\n",
      "(50538,)\n",
      "(3278, 108, 100)\n",
      "(3278,)\n",
      "(50538, 108, 100)\n",
      "(50538,)\n",
      "(3278, 108, 100)\n",
      "(3278,)\n",
      "(50538, 108)\n",
      "(50538,)\n",
      "(3278, 108)\n",
      "(3278,)\n"
     ]
    }
   ],
   "source": [
    "Results = {}\n",
    "\n",
    "# loading_paths = [\n",
    "#     (\"LoadingPath_Non\", \"No\"), \n",
    "#     (\"LoadingPath_PS\", \"Yes\")  \n",
    "# ]\n",
    "\n",
    " \n",
    "loading_paths = [\n",
    "    (LoadingPath_PS, \"Yes\")  \n",
    "]\n",
    "\n",
    "for loading_path, pre_alignment_condition in loading_paths:\n",
    "    print(f\"Processing {loading_path} with PreAlignmentCondition = {pre_alignment_condition}\")\n",
    "    \n",
    "    # Loop through each subject\n",
    "    for subject_id in [0]:#subject_ids:\n",
    "        print(f\"Loading data for Subject {subject_id}...\")\n",
    "        \n",
    "        # Load the subject data\n",
    "        subject_data = load_subject_data(loading_path, subject_id, n_components=Nc, PreAlignment=pre_alignment_condition)\n",
    "        \n",
    "        # Dataset\n",
    "        X_train_dataset = subject_data[\"X_train_dataset\"]\n",
    "        Y_train_dataset = subject_data[\"Y_train_dataset\"]\n",
    "        X_test_dataset = subject_data[\"X_test_dataset\"]\n",
    "        Y_test_dataset = subject_data[\"Y_test_dataset\"]\n",
    "        \n",
    "        # Projected\n",
    "        X_train_projected = subject_data[\"X_train_projected\"]\n",
    "        Y_train_projected = subject_data[\"Y_train_projected\"]\n",
    "        X_test_projected = subject_data[\"X_test_projected\"]\n",
    "        Y_test_projected = subject_data[\"Y_test_projected\"]\n",
    "        \n",
    "        # Features\n",
    "        X_train_features = subject_data[\"X_train_features\"]\n",
    "        Y_train_features = subject_data[\"Y_train_features\"]\n",
    "        X_test_features = subject_data[\"X_test_features\"]\n",
    "        Y_test_features = subject_data[\"Y_test_features\"]\n",
    "        \n",
    "        # Sanity check\n",
    "        print(X_train_dataset.shape)\n",
    "        print(Y_train_dataset.shape)\n",
    "        print(X_test_dataset.shape)\n",
    "        print(Y_test_dataset.shape)\n",
    "\n",
    "        print(X_train_projected.shape) \n",
    "        print(Y_train_projected.shape)\n",
    "        print(X_test_projected.shape) \n",
    "        print(Y_test_projected.shape)\n",
    "\n",
    "        print(X_train_features.shape) \n",
    "        print(Y_train_features.shape)\n",
    "        print(X_test_features.shape)\n",
    "        print(Y_test_features.shape)\n",
    "        \n",
    "        # Implement classification methods\n",
    "        #RG_Metrics = RiemannianGeometry(X_train_dataset, Y_train_dataset, X_test_dataset, Y_test_dataset, metric='riemann', C=1.0, kernel='linear')\n",
    "        #SpatFilt_A_Rie_Metrics = SpatFilt_A_Rie(X_train_projected, Y_train_projected, X_test_projected, Y_test_dataset, metric='riemann', C=1.0, kernel='linear')\n",
    "        #CSP_R_Rie_Metrics = CSP_R_Rie(X_train_dataset, Y_train_dataset, X_test_dataset, Y_test_dataset, nfilter=Nc, metric='riemann', log=False, C=1.0, kernel='linear')\n",
    "        Concat_Metrics = Concat(X_train_dataset, Y_train_dataset, X_test_dataset, Y_test_dataset, X_train_features, X_test_features, metric='riemann', C=1.0, kernel='linear')\n",
    "        \n",
    "        # Store the results for each subject\n",
    "        if subject_id not in Results:\n",
    "            Results[subject_id] = {}\n",
    "        \n",
    "        Results[subject_id][f\"{loading_path}_SpatFilt_A_Rie_Metrics\"] = SpatFilt_A_Rie_Metrics\n",
    "        Results[subject_id][f\"{loading_path}_Concat_Metrics\"] = Concat_Metrics\n",
    "        # Results[subject_id][f\"{loading_path}_RG_Metrics\"] = RG_Metrics\n",
    "        # Results[subject_id][f\"{loading_path}_CSP_R_Rie_Metrics\"] = CSP_R_Rie_Metrics\n",
    "        \n",
    "        # Clear variables to free memory\n",
    "        del (\n",
    "            X_train_dataset, Y_train_dataset,\n",
    "            X_test_dataset, Y_test_dataset,\n",
    "            X_train_projected, Y_train_projected,\n",
    "            X_test_projected, Y_test_projected,\n",
    "            X_train_features, Y_train_features,\n",
    "            X_test_features, Y_test_features\n",
    "        )\n",
    "        \n",
    "        print(f\"Cleared data for Subject {subject_id}.\")\n",
    "    \n",
    "print(Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f405bf7-af52-4d24-b42d-adcf8d10cb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Elapsed time:\", elapsed_time/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2ee4f0-3bea-48d6-b476-b958994be175",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Results[0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1072afc4-b30c-4b78-a577-2074dd8b7b98",
   "metadata": {
    "tags": []
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "unique_test, counts_test = np.unique(Y_test_features, return_counts=True)\n",
    "print(dict(zip(unique_test, counts_test)))\n",
    "\n",
    "unique_train, counts_train = np.unique(Y_train_projected, return_counts=True)\n",
    "print(dict(zip(unique_train, counts_train)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0a4d7d62-2366-4d5f-8333-e87f57710710",
   "metadata": {
    "tags": []
   },
   "source": [
    "Results = {}\n",
    "#LoadingPath = '/home/nicole/Documents/AudioCueWalking_analysis/Variables/AdaptVsNon/LOSO_CV/Dataset/Ns_100/Advance/Transformed/IndividualSubjects_Adaptive/TrainingTestingDatasets'\n",
    "#PreAlignmentCondition = 'Yes'\n",
    "for subject_id in subject_ids:\n",
    "    print(f\"Loading data for Subject {subject_id + 1}...\")\n",
    "    subject_data = load_subject_data(LoadingPath, subject_id, n_components=Nc,  PreAlignment = PreAlignmentCondition)\n",
    "    \n",
    "    # Dataset\n",
    "    X_train_dataset = subject_data[\"X_train_dataset\"]\n",
    "    Y_train_dataset = subject_data[\"Y_train_dataset\"]\n",
    "    X_test_dataset = subject_data[\"X_test_dataset\"]\n",
    "    Y_test_dataset = subject_data[\"Y_test_dataset\"]\n",
    "    \n",
    "    # Projected\n",
    "    X_train_projected = subject_data[\"X_train_projected\"]\n",
    "    Y_train_projected = subject_data[\"Y_train_projected\"]\n",
    "    X_test_projected = subject_data[\"X_test_projected\"]\n",
    "    Y_test_projected = subject_data[\"Y_test_projected\"]\n",
    "    \n",
    "    # Features\n",
    "        \n",
    "    X_train_features =  subject_data[\"X_train_features\"]\n",
    "    Y_train_features = subject_data[\"Y_train_features\"]\n",
    "    X_test_features = subject_data[\"X_test_features\"]\n",
    "    Y_test_features = subject_data[\"Y_test_features\"]\n",
    "    \n",
    "    \n",
    "    # Sanity check\n",
    "    print(X_train_dataset.shape)\n",
    "    print(Y_train_dataset.shape)\n",
    "    print(X_test_dataset.shape)\n",
    "    print(Y_test_dataset.shape)\n",
    "\n",
    "\n",
    "    print(X_train_projected.shape) \n",
    "    print(Y_train_projected.shape)\n",
    "    print(X_test_projected.shape) \n",
    "    print(Y_test_projected.shape)\n",
    "\n",
    "    print(X_train_features.shape) \n",
    "    print(Y_train_features.shape)\n",
    "    print(X_test_features.shape)\n",
    "    print(Y_test_features.shape)\n",
    "    \n",
    "    # Implement classification methods \n",
    "    #RG_Metrics = RiemannianGeometry(X_train_dataset, Y_train_dataset, X_test_dataset, Y_test_dataset, metric='riemann', C=1.0, kernel='linear')\n",
    "    SpatFilt_A_Rie_Metrics = SpatFilt_A_Rie(X_train_projected, Y_train_projected, X_test_projected, Y_test_dataset, metric='riemann', C=1.0, kernel='linear')\n",
    "    #CSP_R_Rie_Metrics = CSP_R_Rie(X_train_dataset, Y_train_dataset, X_test_dataset, Y_test_dataset, nfilter=Nc, metric='riemann', log=False, C=1.0, kernel='linear')\n",
    "    Concat_Metrics = Concat(X_train_dataset, Y_train_dataset, X_test_dataset, Y_test_dataset, X_train_features, X_test_features, metric='riemann', C=1.0, kernel='linear')\n",
    "    \n",
    "    \n",
    "    Results[subject_id] = {\n",
    "        #\"RG_Metrics\": RG_Metrics,\n",
    "        \"SpatFilt_A_Rie_Metrics\": SpatFilt_A_Rie_Metrics,\n",
    "        #\"CSP_R_Rie_Metrics\": CSP_R_Rie_Metrics,\n",
    "        \"Concat_Metrics\": Concat_Metrics\n",
    "    }\n",
    "    \n",
    "    # Clear variables to free memory\n",
    "    del (\n",
    "        X_train_dataset, Y_train_dataset,\n",
    "        X_test_dataset, Y_test_dataset,\n",
    "        X_train_projected, Y_train_projected,\n",
    "        X_test_projected, Y_test_projected,\n",
    "        X_train_features, Y_train_features,\n",
    "        X_test_features, Y_test_features\n",
    "    )\n",
    "    print(f\"Cleared data for Subject {subject_id + 1}.\")\n",
    "    \n",
    "print(Results)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e1b75bc6-2c56-4cfd-ae43-ba36b756a79d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230aa6ec-c371-4891-9a30-c1f55250ca4e",
   "metadata": {},
   "source": [
    "# Finish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea691950-bf25-45f8-84f3-444344ae9969",
   "metadata": {},
   "source": [
    "# Subset testing"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a905ae95-5c8e-45fe-a849-f95d105ff295",
   "metadata": {
    "tags": []
   },
   "source": [
    "subject_ids = [2]  # Replace with your subject IDs\n",
    "Results = {}\n",
    "\n",
    "for subject_id in subject_ids:\n",
    "    print(f\"Loading data for Subject {subject_id + 1}...\")\n",
    "    subject_data = load_subject_data(LoadingPath, subject_id, n_components=Nc)\n",
    "    \n",
    "    random_indices_train = np.random.choice(subject_data[\"X_train_dataset\"].shape[0], size=100, replace=False)\n",
    "    random_indices_test = np.random.choice(subject_data[\"X_test_dataset\"].shape[0], size=100, replace=False)\n",
    "    \n",
    "    # Dataset\n",
    "    X_train_dataset = subject_data[\"X_train_dataset\"][random_indices_train,:,:]\n",
    "    Y_train_dataset = subject_data[\"Y_train_dataset\"][random_indices_train]\n",
    "    X_test_dataset = subject_data[\"X_test_dataset\"][random_indices_test,:,:]\n",
    "    Y_test_dataset = subject_data[\"Y_test_dataset\"][random_indices_test]\n",
    "    \n",
    "    # Projected\n",
    "    X_train_projected = subject_data[\"X_train_projected\"][random_indices_train,:,:]\n",
    "    Y_train_projected = subject_data[\"Y_train_projected\"][random_indices_train]\n",
    "    X_test_projected = subject_data[\"X_test_projected\"][random_indices_test,:,:]\n",
    "    Y_test_projected = subject_data[\"X_test_projected\"][random_indices_test]\n",
    "    \n",
    "    # Features\n",
    "        \n",
    "    X_train_features =  subject_data[\"X_train_features\"][random_indices_train,:]\n",
    "    Y_train_features = subject_data[\"Y_train_features\"][random_indices_train]\n",
    "    X_test_features = subject_data[\"X_test_features\"][random_indices_test,:]\n",
    "    Y_test_features = subject_data[\"Y_test_features\"][random_indices_test]\n",
    "    \n",
    "    \n",
    "    # Sanity check\n",
    "    print(X_train_dataset.shape)\n",
    "    print(Y_train_dataset.shape)\n",
    "    print(X_test_dataset.shape)\n",
    "    print(Y_test_dataset.shape)\n",
    "\n",
    "\n",
    "    print(X_train_projected.shape) \n",
    "    print(Y_train_projected.shape)\n",
    "    print(X_test_projected.shape) \n",
    "    print(Y_test_projected.shape)\n",
    "\n",
    "    print(X_train_features.shape) \n",
    "    print(Y_train_features.shape)\n",
    "    print(X_test_features.shape)\n",
    "    print(Y_test_features.shape)\n",
    "    \n",
    "    # Implement classification methods \n",
    "    RG_Metrics = RiemannianGeometry(X_train_dataset, Y_train_dataset, X_test_dataset, Y_test_dataset, metric='riemann', C=1.0, kernel='linear')\n",
    "    SpatFilt_A_Rie_Metrics = SpatFilt_A_Rie(X_train_projected, Y_train_projected, X_test_projected, Y_test_dataset, metric='riemann', C=1.0, kernel='linear')\n",
    "    CSP_R_Rie_Metrics = CSP_R_Rie(X_train_dataset, Y_train_dataset, X_test_dataset, Y_test_dataset, nfilter=Nc, metric='riemann', log=False, C=1.0, kernel='linear')\n",
    "    Concat_Metrics = Concat(X_train_dataset, Y_train_dataset, X_test_dataset, Y_test_dataset, X_train_features, X_test_features, metric='riemann', C=1.0, kernel='linear')\n",
    "    \n",
    "    \n",
    "    Results[subject_id] = {\n",
    "        \"RG_Metrics\": RG_Metrics,\n",
    "        \"SpatFilt_A_Rie_Metrics\": SpatFilt_A_Rie_Metrics,\n",
    "        \"CSP_R_Rie_Metrics\": CSP_R_Rie_Metrics,\n",
    "        \"Concat_Metrics\": Concat_Metrics\n",
    "    }\n",
    "    \n",
    "    # Clear variables to free memory\n",
    "    del (\n",
    "        X_train_dataset, Y_train_dataset,\n",
    "        X_test_dataset, Y_test_dataset,\n",
    "        X_train_projected, Y_train_projected,\n",
    "        X_test_projected, Y_test_projected,\n",
    "        X_train_features, Y_train_features,\n",
    "        X_test_features, Y_test_features\n",
    "    )\n",
    "    print(f\"Cleared data for Subject {subject_id + 1}.\")\n",
    "    \n",
    "print(Results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyRiemann",
   "language": "python",
   "name": "pyriemann"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
